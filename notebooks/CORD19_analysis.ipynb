{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50721c9f",
   "metadata": {},
   "source": [
    "# CORD-19 Data Analysis\n",
    "\n",
    "This notebook provides a beginner-friendly analysis of the **CORD-19 research dataset** (COVID-19 Open Research Dataset).  \n",
    "We focus on the `metadata.csv` file, which contains information about research papers such as:\n",
    "\n",
    "- Titles and abstracts  \n",
    "- Authors and journals  \n",
    "- Publication dates  \n",
    "- Sources  \n",
    "\n",
    "The goals of this analysis are:\n",
    "1. Explore the structure of the dataset.  \n",
    "2. Clean and prepare the data.  \n",
    "3. Perform basic visualizations (publications per year, top journals, word frequency).  \n",
    "4. Reflect on key insights.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54072e50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6cc279",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load metadata.csv (sample or full file)\n",
    "df = pd.read_csv('../data/metadata.csv')\n",
    "\n",
    "# Display first 5 rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63d8b4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Shape of dataset (rows, columns)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe569ac2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# General info about columns and data types\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bad5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72be6d",
   "metadata": {},
   "source": [
    "We can see that some columns contain missing values, especially in **abstracts** and **journals**.  \n",
    "For this analysis, we will focus on:  \n",
    "\n",
    "- `title`  \n",
    "- `abstract`  \n",
    "- `authors`  \n",
    "- `journal`  \n",
    "- `publish_time`  \n",
    "- `source_x`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0740399",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows without title or publish_time\n",
    "df_clean = df.dropna(subset=['title', 'publish_time'])\n",
    "\n",
    "# Convert publish_time to datetime\n",
    "df_clean['publish_time'] = pd.to_datetime(df_clean['publish_time'], errors='coerce')\n",
    "\n",
    "# Drop rows where conversion failed\n",
    "df_clean = df_clean.dropna(subset=['publish_time'])\n",
    "\n",
    "# Extract year\n",
    "df_clean['year'] = df_clean['publish_time'].dt.year\n",
    "\n",
    "# Add abstract word count\n",
    "df_clean['abstract_word_count'] = df_clean['abstract'].fillna(\"\").apply(lambda x: len(x.split()))\n",
    "\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba779bb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "year_counts = df_clean['year'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=year_counts.index, y=year_counts.values, palette='viridis')\n",
    "plt.title(\"Publications by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df27869",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "top_journals = df_clean['journal'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=top_journals.values, y=top_journals.index, palette='magma')\n",
    "plt.title(\"Top 10 Journals Publishing COVID-19 Research\")\n",
    "plt.xlabel(\"Number of Papers\")\n",
    "plt.ylabel(\"Journal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93a922",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Combine all titles\n",
    "titles = ' '.join(df_clean['title'].dropna().tolist()).lower()\n",
    "\n",
    "# Extract words\n",
    "words = re.findall(r'\\b\\w+\\b', titles)\n",
    "\n",
    "# Count word frequency\n",
    "word_counts = Counter(words)\n",
    "common_words = word_counts.most_common(20)\n",
    "\n",
    "# Plot\n",
    "words, counts = zip(*common_words)\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=list(counts), y=list(words), palette='coolwarm')\n",
    "plt.title(\"Top 20 Most Frequent Words in Titles\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Word\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5cfbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "source_counts = df_clean['source_x'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=source_counts.index, y=source_counts.values, palette='pastel')\n",
    "plt.title(\"Distribution of Papers by Source\")\n",
    "plt.xlabel(\"Source\")\n",
    "plt.ylabel(\"Number of Papers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65248c61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Conclusion & Reflection\n",
    "\n",
    "From this basic analysis, we observed:\n",
    "\n",
    "- The majority of COVID-19 research papers were published between **2020 and 2021**, showing the global urgency of the pandemic.  \n",
    "- Journals such as *Lancet, Nature Medicine,* and *Science* contributed significantly to publishing COVID-19 research.  \n",
    "- Frequent words in titles included \"COVID-19\", \"SARS-CoV-2\", \"health\", and \"pandemic\".  \n",
    "- Sources like **PMC** and **Elsevier** provided many papers in this dataset.  \n",
    "\n",
    "### Reflection\n",
    "- A challenge was dealing with **missing values** (e.g., abstracts and journals were often missing).  \n",
    "- Parsing dates also required cleaning since some rows had invalid formats.  \n",
    "- I learned how to clean, analyze, and visualize real-world datasets using **pandas, matplotlib, and seaborn**.  \n",
    "- This assignment also introduced me to **Streamlit** for building an interactive data app.  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
